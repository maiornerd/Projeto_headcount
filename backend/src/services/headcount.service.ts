// Conte√∫do para: src/services/headcount.service.ts (VERS√ÉO CORRIGIDA)

import { prisma } from '../prisma';
import { Prisma } from '@prisma/client';
import * as XLSX from 'xlsx'; // Importe o XLSX aqui no topo
import * as fs from 'fs'; // File System, para escrever o backup
import * as path from 'path';
import { auditService } from './audit.service';

export class HeadcountService {

  // -----------------------------------------------------------------
  // M√âTODO ANTIGO (J√Å EXISTENTE)
  // -----------------------------------------------------------------
  public async getHeadcountData(query: any) {
    
    // --- 1. PARSE DOS PAR√ÇMETROS ---
    const page = parseInt(query.page || '1');
    const pageSize = parseInt(query.pageSize || '20');
    const sortField = query.sortField || 'desc_sec_hc'; 
    const sortOrder = query.sortOrder || 'asc';
    
    const gestor = query.gestor_area_hc;
    const funcao = query.cod_funcao;
    const macroArea = query.macro_area;
    const buscaGlobal = query.buscaGlobal; 

    const skip = (page - 1) * pageSize;
    const take = pageSize;

    // --- 2. CALCULAR O REALIZADO (Exatamente como antes) ---
    const realizadoCounts = await prisma.employee.groupBy({
      by: ['funcao_codigo'],
      where: {
        status: { in: ["ativo", "F√©rias", "Licen√ßa Maternidade"] }
      },
      _count: { matricula: true }
    });

    const realizadoMap = new Map<string, number>();
    for (const group of realizadoCounts) {
      realizadoMap.set(group.funcao_codigo, group._count.matricula);
    }

    // --- 3. CONSTRUIR O 'WHERE' DIN√ÇMICO ---
    
    // Inicializa o 'where' principal como um objeto vazio
    const where: Prisma.HeadcountWhereInput = {};

    // Cria um array SEPARADO para as condi√ß√µes 'AND'
    const andConditions: Prisma.HeadcountWhereInput[] = [];

    // Agora podemos usar .push() neste array sem erros
    if (gestor) {
      andConditions.push({ gestor_area_hc: { contains: gestor, mode: 'insensitive' } });
    }
    if (funcao) {
      andConditions.push({ cod_funcao: { equals: funcao } });
    }
    if (macroArea) {
      andConditions.push({ macro_area: { equals: macroArea } });
    }

    // Se tivermos alguma condi√ß√£o, n√≥s as adicionamos ao 'where'
    if (andConditions.length > 0) {
      where.AND = andConditions;
    }
    
    // Filtro de Busca Global (permanece igual)
    if (buscaGlobal) {
      where.OR = [
        { desc_funcao: { contains: buscaGlobal, mode: 'insensitive' } },
        { desc_sec_hc: { contains: buscaGlobal, mode: 'insensitive' } },
        { gestor_area_hc: { contains: buscaGlobal, mode: 'insensitive' } },
      ];
    }

    // --- 4. EXECUTAR QUERIES (Pagina√ß√£o e Contagem) ---
    const [totalItems, orcadoData] = await prisma.$transaction([
      prisma.headcount.count({ where }),
      prisma.headcount.findMany({
        where,
        orderBy: {
          [sortField]: sortOrder
        },
        skip: skip,
        take: take
      })
    ]);

    // --- 5. JUNTAR OR√áADO + REALIZADO ---
    const resultadoFinal = orcadoData.map(linhaOrcado => {
     const realizado = realizadoMap.get(linhaOrcado.cod_funcao) || 0;
      
      // L√≥gica do 'orcado' (baseada no seed)
      // TODO: Melhorar esta l√≥gica para ser din√¢mica (pegar o m√™s atual)
      const orcado = (linhaOrcado.qtd_orc_historico as any)['10/2025'] || 0;
      const saldo = orcado - realizado;

      return {
       ...linhaOrcado,
        id: linhaOrcado.id, // Garante que o ID existe para o DataGrid
        qtd_orc: orcado,
        realizado: realizado, // padroniza para min√∫sculo
        saldo: saldo,
     };
   });

    // --- 6. RETORNAR O NOVO OBJETO DE DADOS ---
    return {
      totalItems: totalItems,
      totalPages: Math.ceil(totalItems / pageSize),
      currentPage: page,
      pageSize: pageSize,
      data: resultadoFinal 
    };
  }

  // -----------------------------------------------------------------
  // NOVO M√âTODO (COM A CORRE√á√ÉO)
  // -----------------------------------------------------------------

  /**
   * Processa um arquivo de upload e retorna um preview
   * @param filePath O caminho do arquivo salvo pelo Multer (ex: 'uploads/123-arquivo.xlsx')
   */
  /**
   * Processa um arquivo de upload e retorna um preview
   * @param filePath O caminho do arquivo salvo pelo Multer (ex: 'uploads/123-arquivo.xlsx')
   */
  public async getUploadPreview(filePath: string) {
    try {
      // 1. Ler o arquivo do disco
      const workbook = XLSX.readFile(filePath);

      // 2. Pegar o nome da primeira planilha (COM VERIFICA√á√ÉO ROBUSTA)
      if (!workbook.SheetNames || workbook.SheetNames.length === 0) {
        throw new Error('O arquivo Excel n√£o cont√©m planilhas (sheets).');
      }
      
      const sheetName = workbook.SheetNames[0];

      // **** üëá CORRE√á√ÉO EXPL√çCITA AQUI üëá ****
      // Verifica√ß√£o extra para garantir ao TypeScript que sheetName n√£o √© nulo
      if (!sheetName) {
        throw new Error('N√£o foi poss√≠vel encontrar o nome da primeira planilha.');
      }
      // Agora o TypeScript sabe que sheetName √© 100% string
      const worksheet = workbook.Sheets[sheetName]; 
      // **** üëÜ FIM DA CORRE√á√ÉO üëÜ ****

      if (!worksheet) {
          throw new Error(`A planilha '${sheetName}' n√£o p√¥de ser lida.`);
      }

      // 3. Converter a planilha para JSON
      const data = XLSX.utils.sheet_to_json(worksheet, { header: 1 });

      if (!data || data.length === 0) {
        throw new Error('Planilha est√° vazia ou em formato irreconhec√≠vel.');
      }

      // 4. Separar Cabe√ßalhos e Linhas de Dados
      const headers = data[0] as string[];
      const rows = data.slice(1); 

      // 5. Retorna o preview (cabe√ßalhos + 10 primeiras linhas)
      return {
        headers: headers,
        previewRows: rows.slice(0, 10), // Mostra s√≥ as 10 primeiras
        totalRows: rows.length,
        sheetName: sheetName,
        originalFilePath: filePath // Guardamos para o pr√≥ximo passo (salvar)
      };

    } catch (error: any) {
      throw new Error(`Erro ao ler o arquivo: ${error.message}`);
    }
  }

  /**
   * Confirma o upload, faz backup e atualiza o banco de dados 'Employee'
   * @param filePath O caminho do arquivo (ex: 'uploads/123-arquivo.xlsx')
   * @param userId O ID do usu√°rio que est√° fazendo o upload (para logs)
   */
  public async confirmUpload(filePath: string, userId: string) {
    
    // --- 1. FAZER BACKUP ---
    console.log('Iniciando backup dos funcion√°rios...');
    const backupFileName = `backup-employees-${new Date().toISOString().replace(/:/g, '-')}.json`;
    const backupFilePath = path.join('backups', backupFileName);

    try {
      const currentEmployees = await prisma.employee.findMany();
      fs.writeFileSync(backupFilePath, JSON.stringify(currentEmployees, null, 2));
      console.log(`Backup criado em: ${backupFilePath}`);
    } catch (backupError: any) {
      throw new Error(`Falha ao criar backup: ${backupError.message}`);
    }

    // --- 2. LER O ARQUIVO (DE NOVO) ---
    let rows: any[][];
    let headers: string[];

    try {
      const workbook = XLSX.readFile(filePath);
      const sheetName = workbook.SheetNames[0];
      if (!sheetName) throw new Error('Nome da planilha n√£o encontrado.');
      
      const worksheet = workbook.Sheets[sheetName];
      if (!worksheet) throw new Error('Planilha n√£o p√¥de ser lida.');
      
      // **** üëá CORRE√á√ÉO AQUI üëá ****
      // Dizemos ao TS que esperamos que 'data' seja um array de arrays (any[][])
      const data = XLSX.utils.sheet_to_json(worksheet, { header: 1 }) as any[][];
      // **** üëÜ FIM DA CORRE√á√ÉO üëÜ ****

      if (!data || data.length < 2) throw new Error('Planilha vazia.');
      
      headers = data[0] as string[]; // Agora isso √© seguro (data[0] √© any[])
      rows = data.slice(1); // E isso tamb√©m √© seguro (data.slice(1) √© any[][])

    } catch (readError: any) {
      throw new Error(`Erro ao reler o arquivo: ${readError.message}`);
    }

    // --- 3. ATUALIZAR O BANCO (TRANSA√á√ÉO) ---
    // Mapear cabe√ßalhos para os campos do Prisma
    const matriculaIndex = headers.indexOf('matricula');
    const nomeIndex = headers.indexOf('nome');
    const statusIndex = headers.indexOf('status');
    const funcaoCodigoIndex = headers.indexOf('funcao_codigo');

    if (matriculaIndex === -1 || nomeIndex === -1 || statusIndex === -1) {
      // Deleta o arquivo tempor√°rio se a valida√ß√£o falhar
      fs.unlinkSync(filePath);
      throw new Error('Arquivo CSV deve conter as colunas: matricula, nome, status.');
    }

    // Prepara as opera√ß√µes de 'upsert'
    const upsertOperations = rows.map(row => {
      const matricula = String(row[matriculaIndex]);
      const data = {
        matricula: matricula,
        nome: String(row[nomeIndex]),
        status: String(row[statusIndex]),
        funcao_codigo: String(row[funcaoCodigoIndex] || 'N/A'), // Usa N/A se 'funcao_codigo' estiver vazia
        // Valores padr√£o para campos obrigat√≥rios que n√£o est√£o no CSV
        data_nascimento: new Date('1900-01-01'), 
        data_admissao: new Date(),
        funcao_desc: 'N/A',
        setor: 'N/A',
        jornada: 0,
        salario_atual: 0,
      };

      return prisma.employee.upsert({
        where: { matricula: matricula },
        update: data, // O que atualizar se a matr√≠cula j√° existe
        create: data, // O que criar se a matr√≠cula for nova
      });
    });

    try {
      // Executa todas as N opera√ß√µes dentro de UMA transa√ß√£o
      await prisma.$transaction(upsertOperations);
    } catch (dbError: any) {
      // Se o banco falhar, tentamos reverter o backup (l√≥gica de rollback)
      throw new Error(`Erro ao salvar no banco: ${dbError.message}`);
    }

    // --- 4. REGISTRAR O UPLOAD ---
    await auditService.log({
      userId: userId,
      action: 'confirm_upload',
      targetTable: 'Employee',
      details: { file: filePath, rows: upsertOperations.length }
    });
    
    // 5. Limpar o arquivo tempor√°rio
    fs.unlinkSync(filePath);

    return { 
      message: 'Upload conclu√≠do e banco de dados atualizado!',
      totalRowsProcessed: upsertOperations.length,
      backupFile: backupFilePath
    };
  }
  /**
   * Reverte um upload usando o arquivo de backup
   * @param uploadId O ID do registro de Upload
   * @param adminUserId O ID do Admin que est√° fazendo o rollback (para log)
   */
  public async rollbackUpload(uploadId: string, adminUserId: string) {

    // 1. Encontrar o registro do upload
    const uploadRecord = await prisma.upload.findUnique({
      where: { id: uploadId }
    });

    if (!uploadRecord) {
      throw new Error('Registro de upload n√£o encontrado.');
    }
    if (uploadRecord.status === 'Revertido') {
      throw new Error('Este upload j√° foi revertido anteriormente.');
    }
    if (!uploadRecord.backup_reference) {
      throw new Error('Registro de upload n√£o possui um arquivo de backup associado.');
    }

    const backupFilePath = uploadRecord.backup_reference;

    // 2. Ler o arquivo de backup
    let employeesFromBackup: any[];
    try {
      const backupFileContent = fs.readFileSync(backupFilePath, 'utf-8');
      employeesFromBackup = JSON.parse(backupFileContent);
    } catch (readError: any) {
      throw new Error(`Falha ao ler o arquivo de backup: ${readError.message}`);
    }

    // 3. Restaurar o banco (Transa√ß√£o Cr√≠tica)
    try {
      // Converte as datas (que viraram strings no JSON) de volta para Date
      const dataWithDates = employeesFromBackup.map(emp => ({
        ...emp,
        data_nascimento: new Date(emp.data_nascimento),
        data_admissao: new Date(emp.data_admissao)
      }));

      await prisma.$transaction([
        // 1. APAGA TODOS os funcion√°rios atuais
        prisma.employee.deleteMany({}),

        // 2. RECRIA TODOS os funcion√°rios do backup
        prisma.employee.createMany({
          data: dataWithDates
        })
      ]);

    } catch (dbError: any) {
      throw new Error(`Erro ao restaurar o banco de dados: ${dbError.message}`);
    }

    // 4. Atualizar o status do upload
    await prisma.upload.update({
      where: { id: uploadId },
      data: { status: 'Revertido' }
    });

    // 5. Registrar na auditoria (Importante!)
    await prisma.auditLog.create({
      data: {
        user_id: adminUserId,
        action: 'rollback_upload',
        target_table: 'upload',
        target_id: uploadId,
        details: {
          message: `Upload ${uploadId} revertido. Backup ${backupFilePath} restaurado.`
        }
      }
    });

    return { message: 'Rollback conclu√≠do. O banco de dados foi restaurado ao estado anterior.' };
  }

  /**
   * Agrega os dados de Or√ßado vs. Realizado para os gr√°ficos
   */
  public async getDashboardData() {
    
    // --- 1. Calcular o Realizado (copiado do seu 'getHeadcountData') ---
    const realizadoCounts = await prisma.employee.groupBy({
      by: ['funcao_codigo'],
      where: {
        status: { in: ["ativo", "F√©rias", "Licen√ßa Maternidade"] }
      },
      _count: { matricula: true }
    });
    const realizadoMap = new Map<string, number>();
    for (const group of realizadoCounts) {
      realizadoMap.set(group.funcao_codigo, group._count.matricula);
    }

    // --- 2. Buscar TODOS os dados do Or√ßado ---
    // (N√£o podemos usar 'groupBy' do Prisma porque o 'orcado' √© um JSON)
    const allHeadcountRows = await prisma.headcount.findMany();

    // --- 3. Agregar os dados por Macro √Årea (em c√≥digo) ---
    const aggMap = new Map<string, { name: string, Or√ßado: number, Realizado: number }>();

    for (const row of allHeadcountRows) {
      const area = row.macro_area || 'Sem √Årea';
      
      // L√≥gica do Or√ßado (a mesma da sua tabela)
      const orcado = (row.qtd_orc_historico as any)['10/2025'] || 0;
      
      // L√≥gica do Realizado
      const realizado = realizadoMap.get(row.cod_funcao) || 0;

      // Inicializa o mapa se a √°rea for nova
      if (!aggMap.has(area)) {
        aggMap.set(area, { name: area, Or√ßado: 0, Realizado: 0 });
      }

      // Soma os valores
      const current = aggMap.get(area)!;
      current.Or√ßado += orcado;
      current.Realizado += realizado;
    }

    // 4. Converte o Mapa para um Array (que o 'recharts' consegue ler)
    // Ex: [ { name: 'FINAN√áAS', Or√ßado: 4, Realizado: 3 }, ... ]
    return Array.from(aggMap.values());
  }

}